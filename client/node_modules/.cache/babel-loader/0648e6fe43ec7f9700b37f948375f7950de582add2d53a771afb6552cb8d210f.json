{"ast":null,"code":"var _jsxFileName = \"/Users/beluga/Documents/Dev/React/audio_visualizer/client/src/components/VoiceBot.tsx\",\n  _s = $RefreshSig$();\nimport React, { useState, useEffect, useMemo } from \"react\";\nimport io from \"socket.io-client\";\nimport { start, stop, botSpeak } from \"../util/speechRecognition\";\nimport \"./index.css\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst SERVER = \"http://127.0.0.1:8001\";\n//Temporary fix?\nconst socket = io(SERVER, {\n  transports: [\"websocket\"]\n});\nconst VoiceBot = () => {\n  _s();\n  const [listening, setListening] = useState(false);\n  console.log(\"listening: \", listening);\n  const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n  const recognition = useMemo(() => new SpeechRecognition(), [SpeechRecognition]);\n  recognition.lang = \"en-US\";\n  recognition.interimResults = false;\n  recognition.continuous = true;\n\n  // // fn to receive msg from server\n  // const botSpeak = (text: string | undefined) => {\n  //   //  .speechSynthesis (returns obj --> entry point into Web Speech API)\n  //   const synth = window.speechSynthesis;\n  //   //                    SpeechSynthesisUtterance object\n  //   const utterance = new SpeechSynthesisUtterance(text);\n  //   synth.speak(utterance);\n  //   // Note: it's possible to have infinite loop if the bot message includes keywords\n  // };\n\n  const handleStartButton = () => {\n    if (listening) {\n      stop();\n    } else {\n      start();\n    }\n    setListening(!listening);\n  };\n\n  // const handleClick = () => {\n  //   if (listening) {\n  //     recognition.stop();\n  //     botSpeak(\"Until next time!\");\n  //     setListening(false);\n  //   } else {\n  //     botSpeak(\"Yo! What is good?!\");\n  //     recognition.start();\n  //     setListening(true);\n  //   }\n  // };\n\n  useEffect(() => {\n    recognition.onResult = e => {\n      //console.log(e.results); // e.results :SpeechRecognitionResult object\n      const last = e.results.length - 1;\n      const text = e.results[last][0].transcript;\n      socket.emit(\"user message\", text);\n    };\n    recognition.onSpeechEnd = () => {\n      if (listening) {\n        stop();\n        setListening(false);\n      }\n    };\n    recognition.addEventListener(\"error\", e => {\n      console.log(e.error);\n      recognition.stop();\n    });\n  }, [recognition, listening]);\n\n  // open link with user speech\n  useEffect(() => {\n    socket.on(\"bot message\", answer => {\n      const {\n        msg,\n        link\n      } = answer;\n      botSpeak(msg, () => {\n        if (link) {\n          window.open(link, \"_blank\");\n        }\n      });\n    });\n  }, []);\n  return /*#__PURE__*/_jsxDEV(\"button\", {\n    onClick: handleStartButton,\n    children: [/*#__PURE__*/_jsxDEV(\"img\", {\n      alt: \"mic\",\n      src: \"./mic.png\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 104,\n      columnNumber: 7\n    }, this), \"\", listening ? \"Listening ...\" : \"Click to Speak & Surf\"]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 103,\n    columnNumber: 5\n  }, this);\n};\n_s(VoiceBot, \"rhTiCtZm8g3q/JfgUCnyvNuPwpY=\");\n_c = VoiceBot;\nexport default VoiceBot;\nvar _c;\n$RefreshReg$(_c, \"VoiceBot\");","map":{"version":3,"names":["React","useState","useEffect","useMemo","io","start","stop","botSpeak","jsxDEV","_jsxDEV","SERVER","socket","transports","VoiceBot","_s","listening","setListening","console","log","SpeechRecognition","window","webkitSpeechRecognition","recognition","lang","interimResults","continuous","handleStartButton","onResult","e","last","results","length","text","transcript","emit","onSpeechEnd","addEventListener","error","on","answer","msg","link","open","onClick","children","alt","src","fileName","_jsxFileName","lineNumber","columnNumber","_c","$RefreshReg$"],"sources":["/Users/beluga/Documents/Dev/React/audio_visualizer/client/src/components/VoiceBot.tsx"],"sourcesContent":["import React, { useState, useEffect, useMemo } from \"react\";\nimport io from \"socket.io-client\";\n\nimport { start, stop, botSpeak } from \"../util/speechRecognition\";\n\nimport \"./index.css\";\n\nconst SERVER = \"http://127.0.0.1:8001\";\n//Temporary fix?\nconst socket = io(SERVER, {\n  transports: [\"websocket\"],\n});\n\ndeclare global {\n  interface Window {\n    SpeechRecognition: any;\n    webkitSpeechRecognition: any;\n  }\n}\n\nconst VoiceBot: React.FC = () => {\n  const [listening, setListening] = useState(false);\n\n  console.log(\"listening: \", listening);\n\n  const SpeechRecognition =\n    window.SpeechRecognition || window.webkitSpeechRecognition;\n\n  const recognition = useMemo(\n    () => new SpeechRecognition(),\n    [SpeechRecognition]\n  );\n\n  recognition.lang = \"en-US\";\n  recognition.interimResults = false;\n  recognition.continuous = true;\n\n  // // fn to receive msg from server\n  // const botSpeak = (text: string | undefined) => {\n  //   //  .speechSynthesis (returns obj --> entry point into Web Speech API)\n  //   const synth = window.speechSynthesis;\n  //   //                    SpeechSynthesisUtterance object\n  //   const utterance = new SpeechSynthesisUtterance(text);\n  //   synth.speak(utterance);\n  //   // Note: it's possible to have infinite loop if the bot message includes keywords\n  // };\n\n  const handleStartButton = () => {\n    if (listening) {\n      stop();\n    } else {\n      start();\n    }\n    setListening(!listening);\n  };\n\n  // const handleClick = () => {\n  //   if (listening) {\n  //     recognition.stop();\n  //     botSpeak(\"Until next time!\");\n  //     setListening(false);\n  //   } else {\n  //     botSpeak(\"Yo! What is good?!\");\n  //     recognition.start();\n  //     setListening(true);\n  //   }\n  // };\n\n  useEffect(() => {\n    recognition.onResult = (e: { results: string | any[] }) => {\n      //console.log(e.results); // e.results :SpeechRecognitionResult object\n      const last = e.results.length - 1;\n      const text = e.results[last][0].transcript;\n      socket.emit(\"user message\", text);\n    };\n\n    recognition.onSpeechEnd = () => {\n      if (listening) {\n        stop();\n        setListening(false);\n      }\n    };\n\n    recognition.addEventListener(\"error\", (e: { error: any }) => {\n      console.log(e.error);\n      recognition.stop();\n    });\n  }, [recognition, listening]);\n\n  // open link with user speech\n  useEffect(() => {\n    socket.on(\"bot message\", (answer) => {\n      const { msg, link } = answer;\n      botSpeak(msg, () => {\n        if (link) {\n          window.open(link, \"_blank\");\n        }\n      });\n    });\n  }, []);\n\n  return (\n    <button onClick={handleStartButton}>\n      <img alt=\"mic\" src=\"./mic.png\" />{\"\"}\n      {listening ? \"Listening ...\" : \"Click to Speak & Surf\"}\n    </button>\n  );\n};\n\nexport default VoiceBot;\n"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,QAAQ,EAAEC,SAAS,EAAEC,OAAO,QAAQ,OAAO;AAC3D,OAAOC,EAAE,MAAM,kBAAkB;AAEjC,SAASC,KAAK,EAAEC,IAAI,EAAEC,QAAQ,QAAQ,2BAA2B;AAEjE,OAAO,aAAa;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAErB,MAAMC,MAAM,GAAG,uBAAuB;AACtC;AACA,MAAMC,MAAM,GAAGP,EAAE,CAACM,MAAM,EAAE;EACxBE,UAAU,EAAE,CAAC,WAAW;AAC1B,CAAC,CAAC;AASF,MAAMC,QAAkB,GAAGA,CAAA,KAAM;EAAAC,EAAA;EAC/B,MAAM,CAACC,SAAS,EAAEC,YAAY,CAAC,GAAGf,QAAQ,CAAC,KAAK,CAAC;EAEjDgB,OAAO,CAACC,GAAG,CAAC,aAAa,EAAEH,SAAS,CAAC;EAErC,MAAMI,iBAAiB,GACrBC,MAAM,CAACD,iBAAiB,IAAIC,MAAM,CAACC,uBAAuB;EAE5D,MAAMC,WAAW,GAAGnB,OAAO,CACzB,MAAM,IAAIgB,iBAAiB,EAAE,EAC7B,CAACA,iBAAiB,CAAC,CACpB;EAEDG,WAAW,CAACC,IAAI,GAAG,OAAO;EAC1BD,WAAW,CAACE,cAAc,GAAG,KAAK;EAClCF,WAAW,CAACG,UAAU,GAAG,IAAI;;EAE7B;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;;EAEA,MAAMC,iBAAiB,GAAGA,CAAA,KAAM;IAC9B,IAAIX,SAAS,EAAE;MACbT,IAAI,EAAE;IACR,CAAC,MAAM;MACLD,KAAK,EAAE;IACT;IACAW,YAAY,CAAC,CAACD,SAAS,CAAC;EAC1B,CAAC;;EAED;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;;EAEAb,SAAS,CAAC,MAAM;IACdoB,WAAW,CAACK,QAAQ,GAAIC,CAA8B,IAAK;MACzD;MACA,MAAMC,IAAI,GAAGD,CAAC,CAACE,OAAO,CAACC,MAAM,GAAG,CAAC;MACjC,MAAMC,IAAI,GAAGJ,CAAC,CAACE,OAAO,CAACD,IAAI,CAAC,CAAC,CAAC,CAAC,CAACI,UAAU;MAC1CtB,MAAM,CAACuB,IAAI,CAAC,cAAc,EAAEF,IAAI,CAAC;IACnC,CAAC;IAEDV,WAAW,CAACa,WAAW,GAAG,MAAM;MAC9B,IAAIpB,SAAS,EAAE;QACbT,IAAI,EAAE;QACNU,YAAY,CAAC,KAAK,CAAC;MACrB;IACF,CAAC;IAEDM,WAAW,CAACc,gBAAgB,CAAC,OAAO,EAAGR,CAAiB,IAAK;MAC3DX,OAAO,CAACC,GAAG,CAACU,CAAC,CAACS,KAAK,CAAC;MACpBf,WAAW,CAAChB,IAAI,EAAE;IACpB,CAAC,CAAC;EACJ,CAAC,EAAE,CAACgB,WAAW,EAAEP,SAAS,CAAC,CAAC;;EAE5B;EACAb,SAAS,CAAC,MAAM;IACdS,MAAM,CAAC2B,EAAE,CAAC,aAAa,EAAGC,MAAM,IAAK;MACnC,MAAM;QAAEC,GAAG;QAAEC;MAAK,CAAC,GAAGF,MAAM;MAC5BhC,QAAQ,CAACiC,GAAG,EAAE,MAAM;QAClB,IAAIC,IAAI,EAAE;UACRrB,MAAM,CAACsB,IAAI,CAACD,IAAI,EAAE,QAAQ,CAAC;QAC7B;MACF,CAAC,CAAC;IACJ,CAAC,CAAC;EACJ,CAAC,EAAE,EAAE,CAAC;EAEN,oBACEhC,OAAA;IAAQkC,OAAO,EAAEjB,iBAAkB;IAAAkB,QAAA,gBACjCnC,OAAA;MAAKoC,GAAG,EAAC,KAAK;MAACC,GAAG,EAAC;IAAW;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,QAAG,EAAC,EAAE,EACnCnC,SAAS,GAAG,eAAe,GAAG,uBAAuB;EAAA;IAAAgC,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,QAC/C;AAEb,CAAC;AAACpC,EAAA,CAvFID,QAAkB;AAAAsC,EAAA,GAAlBtC,QAAkB;AAyFxB,eAAeA,QAAQ;AAAC,IAAAsC,EAAA;AAAAC,YAAA,CAAAD,EAAA"},"metadata":{},"sourceType":"module","externalDependencies":[]}