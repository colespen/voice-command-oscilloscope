{"ast":null,"code":"var _jsxFileName = \"/Users/beluga/Documents/Dev/React/audio_visualizer/client/src/components/VoiceBot.tsx\",\n  _s = $RefreshSig$();\nimport React, { useState, useEffect, useMemo } from \"react\";\nimport io from \"socket.io-client\";\nimport \"./index.css\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst SERVER = \"http://127.0.0.1:8001\";\n//Temporary fix?\nconst socket = io(SERVER, {\n  transports: [\"websocket\"]\n});\nconst VoiceBot = () => {\n  _s();\n  const [listening, setListening] = useState(false);\n  console.log(\"listening: \", listening);\n  const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n  const recognition = useMemo(() => new SpeechRecognition(), [SpeechRecognition]);\n  recognition.lang = \"en-US\";\n  recognition.interimResults = false;\n  recognition.continuous = true;\n\n  // fn to receive msg from server\n  const botSpeak = text => {\n    //  .speechSynthesis (returns obj --> entry point into Web Speech API)\n    const synth = window.speechSynthesis;\n    //                    SpeechSynthesisUtterance object\n    const utterance = new SpeechSynthesisUtterance(text);\n    synth.speak(utterance);\n    // Note: it's possible to have infinite loop if the bot message includes keywords\n  };\n\n  // const handleStartButton = () => {\n  //   if (listening) {\n  //     stop();\n  //   } else {\n  //     start();\n  //   }\n  //   setListening(!listening);\n  // };\n\n  const handleClick = () => {\n    if (listening) {\n      recognition.stop();\n      botSpeak(\"Until next time!\");\n      setListening(false);\n    } else {\n      botSpeak(\"Yo! What is good?!\");\n      recognition.start();\n      setListening(true);\n    }\n  };\n  useEffect(() => {\n    recognition.onResult = e => {\n      //console.log(e.results); // e.results :SpeechRecognitionResult object\n      const last = e.results.length - 1;\n      const text = e.results[last][0].transcript;\n      socket.emit(\"user message\", text);\n    };\n    recognition.onSpeechEnd = () => {\n      if (listening) {\n        recognition.stop();\n      } else {\n        return null;\n      }\n    };\n    recognition.addEventListener(\"error\", e => {\n      console.log(e.error);\n      recognition.stop();\n    });\n  }, [recognition]);\n\n  // open link with user speech\n  useEffect(() => {\n    socket.on(\"bot message\", answer => {\n      const {\n        msg,\n        link\n      } = answer;\n      botSpeak(msg);\n      if (link) {\n        window.open(link, \"_blank\");\n      }\n    });\n  }, []);\n  return /*#__PURE__*/_jsxDEV(\"button\", {\n    onClick: handleClick,\n    children: [/*#__PURE__*/_jsxDEV(\"img\", {\n      alt: \"mic\",\n      src: \"./mic.png\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 105,\n      columnNumber: 7\n    }, this), \"\", listening ? \"Listening ...\" : \"Click to Speak & Surf\"]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 104,\n    columnNumber: 5\n  }, this);\n};\n_s(VoiceBot, \"rhTiCtZm8g3q/JfgUCnyvNuPwpY=\");\n_c = VoiceBot;\nexport default VoiceBot;\nvar _c;\n$RefreshReg$(_c, \"VoiceBot\");","map":{"version":3,"names":["React","useState","useEffect","useMemo","io","jsxDEV","_jsxDEV","SERVER","socket","transports","VoiceBot","_s","listening","setListening","console","log","SpeechRecognition","window","webkitSpeechRecognition","recognition","lang","interimResults","continuous","botSpeak","text","synth","speechSynthesis","utterance","SpeechSynthesisUtterance","speak","handleClick","stop","start","onResult","e","last","results","length","transcript","emit","onSpeechEnd","addEventListener","error","on","answer","msg","link","open","onClick","children","alt","src","fileName","_jsxFileName","lineNumber","columnNumber","_c","$RefreshReg$"],"sources":["/Users/beluga/Documents/Dev/React/audio_visualizer/client/src/components/VoiceBot.tsx"],"sourcesContent":["import React, { useState, useEffect, useMemo } from \"react\";\nimport io from \"socket.io-client\";\n\nimport { start, stop } from \"../util/speechRecognition\";\n\nimport \"./index.css\";\n\nconst SERVER = \"http://127.0.0.1:8001\";\n//Temporary fix?\nconst socket = io(SERVER, {\n  transports: [\"websocket\"],\n});\n\ndeclare global {\n  interface Window {\n    SpeechRecognition: any;\n    webkitSpeechRecognition: any;\n  }\n}\n\nconst VoiceBot: React.FC = () => {\n  const [listening, setListening] = useState(false);\n\n  console.log(\"listening: \", listening);\n\n  const SpeechRecognition =\n    window.SpeechRecognition || window.webkitSpeechRecognition;\n\n  const recognition = useMemo(\n    () => new SpeechRecognition(),\n    [SpeechRecognition]\n  );\n\n  recognition.lang = \"en-US\";\n  recognition.interimResults = false;\n  recognition.continuous = true;\n\n  // fn to receive msg from server\n  const botSpeak = (text: string | undefined) => {\n    //  .speechSynthesis (returns obj --> entry point into Web Speech API)\n    const synth = window.speechSynthesis;\n    //                    SpeechSynthesisUtterance object\n    const utterance = new SpeechSynthesisUtterance(text);\n    synth.speak(utterance);\n    // Note: it's possible to have infinite loop if the bot message includes keywords\n  };\n\n  // const handleStartButton = () => {\n  //   if (listening) {\n  //     stop();\n  //   } else {\n  //     start();\n  //   }\n  //   setListening(!listening);\n  // };\n\n  const handleClick = () => {\n    if (listening) {\n      recognition.stop();\n      botSpeak(\"Until next time!\");\n      setListening(false);\n    } else {\n      botSpeak(\"Yo! What is good?!\");\n      recognition.start();\n      setListening(true);\n    }\n  };\n\n  useEffect(() => {\n    recognition.onResult = (e: { results: string | any[] }) => {\n      //console.log(e.results); // e.results :SpeechRecognitionResult object\n      const last = e.results.length - 1;\n      const text = e.results[last][0].transcript;\n      socket.emit(\"user message\", text);\n    };\n\n    recognition.onSpeechEnd = () => {\n      if (listening) {\n        recognition.stop();\n      } else {\n        return null\n      }\n      \n    };\n\n    recognition.addEventListener(\"error\", (e: { error: any }) => {\n      console.log(e.error);\n      recognition.stop();\n    });\n  }, [recognition]);\n\n  // open link with user speech\n  useEffect(() => {\n    socket.on(\"bot message\", (answer) => {\n      const { msg, link } = answer;\n      botSpeak(msg);\n      if (link) {\n        window.open(link, \"_blank\");\n      }\n    });\n  }, []);\n\n  return (\n    <button onClick={handleClick}>\n      <img alt=\"mic\" src=\"./mic.png\" />{\"\"}\n      {listening ? \"Listening ...\" : \"Click to Speak & Surf\"}\n    </button>\n  );\n};\n\nexport default VoiceBot;\n"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,QAAQ,EAAEC,SAAS,EAAEC,OAAO,QAAQ,OAAO;AAC3D,OAAOC,EAAE,MAAM,kBAAkB;AAIjC,OAAO,aAAa;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAErB,MAAMC,MAAM,GAAG,uBAAuB;AACtC;AACA,MAAMC,MAAM,GAAGJ,EAAE,CAACG,MAAM,EAAE;EACxBE,UAAU,EAAE,CAAC,WAAW;AAC1B,CAAC,CAAC;AASF,MAAMC,QAAkB,GAAGA,CAAA,KAAM;EAAAC,EAAA;EAC/B,MAAM,CAACC,SAAS,EAAEC,YAAY,CAAC,GAAGZ,QAAQ,CAAC,KAAK,CAAC;EAEjDa,OAAO,CAACC,GAAG,CAAC,aAAa,EAAEH,SAAS,CAAC;EAErC,MAAMI,iBAAiB,GACrBC,MAAM,CAACD,iBAAiB,IAAIC,MAAM,CAACC,uBAAuB;EAE5D,MAAMC,WAAW,GAAGhB,OAAO,CACzB,MAAM,IAAIa,iBAAiB,EAAE,EAC7B,CAACA,iBAAiB,CAAC,CACpB;EAEDG,WAAW,CAACC,IAAI,GAAG,OAAO;EAC1BD,WAAW,CAACE,cAAc,GAAG,KAAK;EAClCF,WAAW,CAACG,UAAU,GAAG,IAAI;;EAE7B;EACA,MAAMC,QAAQ,GAAIC,IAAwB,IAAK;IAC7C;IACA,MAAMC,KAAK,GAAGR,MAAM,CAACS,eAAe;IACpC;IACA,MAAMC,SAAS,GAAG,IAAIC,wBAAwB,CAACJ,IAAI,CAAC;IACpDC,KAAK,CAACI,KAAK,CAACF,SAAS,CAAC;IACtB;EACF,CAAC;;EAED;EACA;EACA;EACA;EACA;EACA;EACA;EACA;;EAEA,MAAMG,WAAW,GAAGA,CAAA,KAAM;IACxB,IAAIlB,SAAS,EAAE;MACbO,WAAW,CAACY,IAAI,EAAE;MAClBR,QAAQ,CAAC,kBAAkB,CAAC;MAC5BV,YAAY,CAAC,KAAK,CAAC;IACrB,CAAC,MAAM;MACLU,QAAQ,CAAC,oBAAoB,CAAC;MAC9BJ,WAAW,CAACa,KAAK,EAAE;MACnBnB,YAAY,CAAC,IAAI,CAAC;IACpB;EACF,CAAC;EAEDX,SAAS,CAAC,MAAM;IACdiB,WAAW,CAACc,QAAQ,GAAIC,CAA8B,IAAK;MACzD;MACA,MAAMC,IAAI,GAAGD,CAAC,CAACE,OAAO,CAACC,MAAM,GAAG,CAAC;MACjC,MAAMb,IAAI,GAAGU,CAAC,CAACE,OAAO,CAACD,IAAI,CAAC,CAAC,CAAC,CAAC,CAACG,UAAU;MAC1C9B,MAAM,CAAC+B,IAAI,CAAC,cAAc,EAAEf,IAAI,CAAC;IACnC,CAAC;IAEDL,WAAW,CAACqB,WAAW,GAAG,MAAM;MAC9B,IAAI5B,SAAS,EAAE;QACbO,WAAW,CAACY,IAAI,EAAE;MACpB,CAAC,MAAM;QACL,OAAO,IAAI;MACb;IAEF,CAAC;IAEDZ,WAAW,CAACsB,gBAAgB,CAAC,OAAO,EAAGP,CAAiB,IAAK;MAC3DpB,OAAO,CAACC,GAAG,CAACmB,CAAC,CAACQ,KAAK,CAAC;MACpBvB,WAAW,CAACY,IAAI,EAAE;IACpB,CAAC,CAAC;EACJ,CAAC,EAAE,CAACZ,WAAW,CAAC,CAAC;;EAEjB;EACAjB,SAAS,CAAC,MAAM;IACdM,MAAM,CAACmC,EAAE,CAAC,aAAa,EAAGC,MAAM,IAAK;MACnC,MAAM;QAAEC,GAAG;QAAEC;MAAK,CAAC,GAAGF,MAAM;MAC5BrB,QAAQ,CAACsB,GAAG,CAAC;MACb,IAAIC,IAAI,EAAE;QACR7B,MAAM,CAAC8B,IAAI,CAACD,IAAI,EAAE,QAAQ,CAAC;MAC7B;IACF,CAAC,CAAC;EACJ,CAAC,EAAE,EAAE,CAAC;EAEN,oBACExC,OAAA;IAAQ0C,OAAO,EAAElB,WAAY;IAAAmB,QAAA,gBAC3B3C,OAAA;MAAK4C,GAAG,EAAC,KAAK;MAACC,GAAG,EAAC;IAAW;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,QAAG,EAAC,EAAE,EACnC3C,SAAS,GAAG,eAAe,GAAG,uBAAuB;EAAA;IAAAwC,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,QAC/C;AAEb,CAAC;AAAC5C,EAAA,CAxFID,QAAkB;AAAA8C,EAAA,GAAlB9C,QAAkB;AA0FxB,eAAeA,QAAQ;AAAC,IAAA8C,EAAA;AAAAC,YAAA,CAAAD,EAAA"},"metadata":{},"sourceType":"module","externalDependencies":[]}