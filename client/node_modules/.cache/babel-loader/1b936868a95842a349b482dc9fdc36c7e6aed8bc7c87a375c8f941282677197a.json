{"ast":null,"code":"var _jsxFileName = \"/Users/beluga/Documents/Dev/React/audio_visualizer/client/src/components/VoiceBot.tsx\",\n  _s = $RefreshSig$();\nimport React, { useState } from \"react\";\nimport io from \"socket.io-client\";\nimport \"./index.css\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst SERVER = \"http://127.0.0.1:8001\";\n//Temporary fix?\nconst socket = io(SERVER, {\n  transports: [\"websocket\"]\n});\nconst VoiceBot = () => {\n  _s();\n  const [listening, setListening] = useState(false);\n  const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n  const recognition = new SpeechRecognition();\n  // const startButton = document.querySelector(\"button\");\n  // const microphone = document.querySelector(\".fa-microphone\");\n  // const output = document.querySelector(\".output\");\n  // const loading = document.querySelector(\".lds-ripple\");\n\n  recognition.lang = \"en-US\";\n  recognition.interimResults = false;\n  recognition.continuous = true;\n  const handleClick = () => {\n    if (listening) {\n      recognition.stop();\n      botSpeak(\"Thanks for dropping by!\");\n      setListening(prev => !prev);\n    } else {\n      botSpeak(\"Yo! What is good?!\");\n      recognition.start();\n      setListening(prev => !prev);\n    }\n    // output.textContent = \"Listening ... \";\n    // loading.classList.add(\"reveal\");\n    // microphone.classList.add(\"hide\");\n  };\n\n  const stop = () => {\n    botSpeak(\"Thanks for dropping by!\");\n    // output.textContent = \"Session ended\";\n    // loading.classList.remove(\"reveal\");\n    // microphone.classList.remove(\"hide\");\n  };\n\n  // startButton.addEventListener(\"click\", () => {\n  //   listening ? stop() : start();\n  //   listening = !listening;\n  // });\n\n  useEffect(() => {});\n  recognition.addEventListener(\"result\", e => {\n    //console.log(e.results); // e.results :SpeechRecognitionResult object\n    const last = e.results.length - 1;\n    const text = e.results[last][0].transcript;\n    socket.emit(\"user message\", text);\n  });\n  recognition.addEventListener(\"speechend\", () => {\n    if (listening) {\n      recognition.stop();\n    } else {\n      return null;\n    }\n    setListening(prev => !prev);\n  });\n  recognition.addEventListener(\"error\", e => {\n    console.log(e.error);\n    stop();\n  });\n\n  // receive message from server\n  const botSpeak = text => {\n    //  .speechSynthesis (returns obj --> entry point into Web Speech API)\n    const synth = window.speechSynthesis;\n    //                    SpeechSynthesisUtterance object --> Web Speech API\n    const utterance = new SpeechSynthesisUtterance(text);\n    synth.speak(utterance);\n    // Note: it's possible to have infinite loop if the bot message includes keywords\n  };\n\n  socket.on(\"bot message\", answer => {\n    const {\n      msg,\n      link\n    } = answer;\n    botSpeak(msg);\n    if (link) {\n      window.open(link, \"_blank\");\n    }\n  });\n  return /*#__PURE__*/_jsxDEV(\"button\", {\n    onClick: handleClick,\n    children: [\"mic:\", listening ? \"Listening ...\" : \"Click to surf\"]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 106,\n    columnNumber: 5\n  }, this);\n};\n_s(VoiceBot, \"WzZv0xKGdAOpCR7XZ1RH2ZldfVA=\");\n_c = VoiceBot;\nexport default VoiceBot;\nvar _c;\n$RefreshReg$(_c, \"VoiceBot\");","map":{"version":3,"names":["React","useState","io","jsxDEV","_jsxDEV","SERVER","socket","transports","VoiceBot","_s","listening","setListening","SpeechRecognition","window","webkitSpeechRecognition","recognition","lang","interimResults","continuous","handleClick","stop","botSpeak","prev","start","useEffect","addEventListener","e","last","results","length","text","transcript","emit","console","log","error","synth","speechSynthesis","utterance","SpeechSynthesisUtterance","speak","on","answer","msg","link","open","onClick","children","fileName","_jsxFileName","lineNumber","columnNumber","_c","$RefreshReg$"],"sources":["/Users/beluga/Documents/Dev/React/audio_visualizer/client/src/components/VoiceBot.tsx"],"sourcesContent":["import React, { useState } from \"react\";\nimport io from \"socket.io-client\";\n\nimport \"./index.css\";\n\nconst SERVER = \"http://127.0.0.1:8001\";\n//Temporary fix?\nconst socket = io(SERVER, {\n  transports: [\"websocket\"],\n});\n\ndeclare global {\n  interface Window {\n    SpeechRecognition: any;\n    webkitSpeechRecognition: any;\n  }\n}\n\nconst VoiceBot: React.FC = () => {\n  const [listening, setListening] = useState(false);\n  const SpeechRecognition =\n    window.SpeechRecognition || window.webkitSpeechRecognition;\n\n  const recognition = new SpeechRecognition();\n  // const startButton = document.querySelector(\"button\");\n  // const microphone = document.querySelector(\".fa-microphone\");\n  // const output = document.querySelector(\".output\");\n  // const loading = document.querySelector(\".lds-ripple\");\n\n  recognition.lang = \"en-US\";\n  recognition.interimResults = false;\n  recognition.continuous = true;\n\n  const handleClick = () => {\n    if (listening) {\n      recognition.stop();\n      botSpeak(\"Thanks for dropping by!\");\n      setListening((prev) => !prev);\n    } else {\n      botSpeak(\"Yo! What is good?!\");\n      recognition.start();\n      setListening((prev) => !prev);\n    }\n    // output.textContent = \"Listening ... \";\n    // loading.classList.add(\"reveal\");\n    // microphone.classList.add(\"hide\");\n  };\n\n  const stop = () => {\n    botSpeak(\"Thanks for dropping by!\");\n    // output.textContent = \"Session ended\";\n    // loading.classList.remove(\"reveal\");\n    // microphone.classList.remove(\"hide\");\n  };\n\n  // startButton.addEventListener(\"click\", () => {\n  //   listening ? stop() : start();\n  //   listening = !listening;\n  // });\n\n  useEffect(() => {\n    \n  })\n\n  recognition.addEventListener(\"result\", (e: { results: string | any[] }) => {\n    //console.log(e.results); // e.results :SpeechRecognitionResult object\n    const last = e.results.length - 1;\n    const text = e.results[last][0].transcript;\n    socket.emit(\"user message\", text);\n  });\n\n  recognition.addEventListener(\"speechend\", () => {\n    if (listening) {\n      recognition.stop();\n    } else {\n      return null;\n    }\n    setListening((prev) => !prev);\n  });\n\n  recognition.addEventListener(\"error\", (e: { error: any }) => {\n    console.log(e.error);\n    stop();\n  });\n\n  // receive message from server\n  const botSpeak = (text: string | undefined) => {\n    //  .speechSynthesis (returns obj --> entry point into Web Speech API)\n    const synth = window.speechSynthesis;\n    //                    SpeechSynthesisUtterance object --> Web Speech API\n    const utterance = new SpeechSynthesisUtterance(text);\n\n    synth.speak(utterance);\n    // Note: it's possible to have infinite loop if the bot message includes keywords\n  };\n\n  socket.on(\"bot message\", (answer) => {\n    const { msg, link } = answer;\n    botSpeak(msg);\n    if (link) {\n      window.open(link, \"_blank\");\n    }\n  });\n\n  return (\n    <button onClick={handleClick}>\n      mic:\n      {listening ? \"Listening ...\" : \"Click to surf\"}\n    </button>\n  );\n};\n\nexport default VoiceBot;\n"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,QAAQ,QAAQ,OAAO;AACvC,OAAOC,EAAE,MAAM,kBAAkB;AAEjC,OAAO,aAAa;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAErB,MAAMC,MAAM,GAAG,uBAAuB;AACtC;AACA,MAAMC,MAAM,GAAGJ,EAAE,CAACG,MAAM,EAAE;EACxBE,UAAU,EAAE,CAAC,WAAW;AAC1B,CAAC,CAAC;AASF,MAAMC,QAAkB,GAAGA,CAAA,KAAM;EAAAC,EAAA;EAC/B,MAAM,CAACC,SAAS,EAAEC,YAAY,CAAC,GAAGV,QAAQ,CAAC,KAAK,CAAC;EACjD,MAAMW,iBAAiB,GACrBC,MAAM,CAACD,iBAAiB,IAAIC,MAAM,CAACC,uBAAuB;EAE5D,MAAMC,WAAW,GAAG,IAAIH,iBAAiB,EAAE;EAC3C;EACA;EACA;EACA;;EAEAG,WAAW,CAACC,IAAI,GAAG,OAAO;EAC1BD,WAAW,CAACE,cAAc,GAAG,KAAK;EAClCF,WAAW,CAACG,UAAU,GAAG,IAAI;EAE7B,MAAMC,WAAW,GAAGA,CAAA,KAAM;IACxB,IAAIT,SAAS,EAAE;MACbK,WAAW,CAACK,IAAI,EAAE;MAClBC,QAAQ,CAAC,yBAAyB,CAAC;MACnCV,YAAY,CAAEW,IAAI,IAAK,CAACA,IAAI,CAAC;IAC/B,CAAC,MAAM;MACLD,QAAQ,CAAC,oBAAoB,CAAC;MAC9BN,WAAW,CAACQ,KAAK,EAAE;MACnBZ,YAAY,CAAEW,IAAI,IAAK,CAACA,IAAI,CAAC;IAC/B;IACA;IACA;IACA;EACF,CAAC;;EAED,MAAMF,IAAI,GAAGA,CAAA,KAAM;IACjBC,QAAQ,CAAC,yBAAyB,CAAC;IACnC;IACA;IACA;EACF,CAAC;;EAED;EACA;EACA;EACA;;EAEAG,SAAS,CAAC,MAAM,CAEhB,CAAC,CAAC;EAEFT,WAAW,CAACU,gBAAgB,CAAC,QAAQ,EAAGC,CAA8B,IAAK;IACzE;IACA,MAAMC,IAAI,GAAGD,CAAC,CAACE,OAAO,CAACC,MAAM,GAAG,CAAC;IACjC,MAAMC,IAAI,GAAGJ,CAAC,CAACE,OAAO,CAACD,IAAI,CAAC,CAAC,CAAC,CAAC,CAACI,UAAU;IAC1CzB,MAAM,CAAC0B,IAAI,CAAC,cAAc,EAAEF,IAAI,CAAC;EACnC,CAAC,CAAC;EAEFf,WAAW,CAACU,gBAAgB,CAAC,WAAW,EAAE,MAAM;IAC9C,IAAIf,SAAS,EAAE;MACbK,WAAW,CAACK,IAAI,EAAE;IACpB,CAAC,MAAM;MACL,OAAO,IAAI;IACb;IACAT,YAAY,CAAEW,IAAI,IAAK,CAACA,IAAI,CAAC;EAC/B,CAAC,CAAC;EAEFP,WAAW,CAACU,gBAAgB,CAAC,OAAO,EAAGC,CAAiB,IAAK;IAC3DO,OAAO,CAACC,GAAG,CAACR,CAAC,CAACS,KAAK,CAAC;IACpBf,IAAI,EAAE;EACR,CAAC,CAAC;;EAEF;EACA,MAAMC,QAAQ,GAAIS,IAAwB,IAAK;IAC7C;IACA,MAAMM,KAAK,GAAGvB,MAAM,CAACwB,eAAe;IACpC;IACA,MAAMC,SAAS,GAAG,IAAIC,wBAAwB,CAACT,IAAI,CAAC;IAEpDM,KAAK,CAACI,KAAK,CAACF,SAAS,CAAC;IACtB;EACF,CAAC;;EAEDhC,MAAM,CAACmC,EAAE,CAAC,aAAa,EAAGC,MAAM,IAAK;IACnC,MAAM;MAAEC,GAAG;MAAEC;IAAK,CAAC,GAAGF,MAAM;IAC5BrB,QAAQ,CAACsB,GAAG,CAAC;IACb,IAAIC,IAAI,EAAE;MACR/B,MAAM,CAACgC,IAAI,CAACD,IAAI,EAAE,QAAQ,CAAC;IAC7B;EACF,CAAC,CAAC;EAEF,oBACExC,OAAA;IAAQ0C,OAAO,EAAE3B,WAAY;IAAA4B,QAAA,GAAC,MAE5B,EAACrC,SAAS,GAAG,eAAe,GAAG,eAAe;EAAA;IAAAsC,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,QACvC;AAEb,CAAC;AAAC1C,EAAA,CA5FID,QAAkB;AAAA4C,EAAA,GAAlB5C,QAAkB;AA8FxB,eAAeA,QAAQ;AAAC,IAAA4C,EAAA;AAAAC,YAAA,CAAAD,EAAA"},"metadata":{},"sourceType":"module","externalDependencies":[]}